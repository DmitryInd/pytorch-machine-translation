---
learning_rate: 0.0001
epoch_num: 5
emb_size: 510
num_heads: 6
num_encoder_layers: 4
num_decoder_layers: 4
dropout: 0.1
div_factor: 10000
try_one_batch: False
path_to_log: "training_logs/transformer_progress_logs"